{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Classifier_gradedassg1",
      "provenance": [],
      "authorship_tag": "ABX9TyMso/uDvay6ziHOmtDCWfQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poohi5/cmpe258_homework/blob/master/Graded_HW1/MNIST_Classifier_gradedassg1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJu5dlywLXII",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**MNIST classifier**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78uf0OeWLZhK",
        "colab_type": "text"
      },
      "source": [
        "###Import MNIST dataset from sklearn's dataset\n",
        "\n",
        "#####Separating target column and data column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnUIXBsOLR6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n",
        "data, target_value = mnist[\"data\"], mnist[\"target\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPmbF88tLcig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd_cFuAfLmwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5046cfdb-b6f2-4ef8-80c3-414edcbe067f"
      },
      "source": [
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mNk9rKwLnuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "209a779b-08a5-41e1-88b7-6b3973998c79"
      },
      "source": [
        "target_value"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjpXZVCfLfzq",
        "colab_type": "text"
      },
      "source": [
        "####Check Nulls if any\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnWOZcXoLfQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4db7d14-f1f5-42d0-abe3-63a20d84b40b"
      },
      "source": [
        "np.isnan(data).any()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbkgZzc7Lq0q",
        "colab_type": "text"
      },
      "source": [
        "####Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AcvKRQwLlV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data/25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87iOYAt0L4HU",
        "colab_type": "text"
      },
      "source": [
        "Building and traning the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnAJcXUQLsWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = 10\n",
        "digit_example = target_value.shape[0]\n",
        "\n",
        "target_value = target_value.reshape(1, digit_example)\n",
        "\n",
        "target_new = np.eye(digits)[target_value.astype('int32')]\n",
        "target_new = target_new.T.reshape(digits, digit_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQRVN9bSMNXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2b1f0e0-62ac-4de1-a9a9-40d2e0707321"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISJXURW0MPN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02530833-a8a9-4d66-b188-31b0aa69185f"
      },
      "source": [
        "target_value.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 70000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKcxYgCCMDfQ",
        "colab_type": "text"
      },
      "source": [
        "###Train and Test Split of digits\n",
        "\n",
        "*   Train data = 60000\n",
        "*   Test data = remaining\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHy3mE1MBSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = 60000\n",
        "d_test = data.shape[0] - d\n",
        "#print(d_test)\n",
        "X_train, X_test = data[:d].T, data[d:].T\n",
        "Y_train, Y_test = target_new[:,:d], target_new[:,d:]\n",
        "\n",
        "shuffle_index = np.random.permutation(d)\n",
        "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy1iRlbSMkhK",
        "colab_type": "text"
      },
      "source": [
        "###Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBa55g_rMchb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1BJKsslMnlr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4c65b1ec-7fe3-4c1d-9776-ebd67523c7a1"
      },
      "source": [
        "#i = 10\n",
        "i =9\n",
        "plt.imshow(X_train[:,i].reshape(28,28))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_train[:,i]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAFKElEQVR4nO3dwYuUdRzH8ZlxV1lwo0OxKYaG2LFD\nQVDUoWApJEgCI+hg1CUMPHjuuKfADhoheBCCoJCQhTqIWF60MKJDsGYYVG5SWkEURM3uTP/Aznfc\nZmbnM/l6Hf3uM89zee8X/LHzNLvdbgPI0xr3AwBrEyeEEieEEieEEieEmqqG8639/isXRuxs51Rz\nrX+3OSGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGU\nOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCFU+QpARmP6/Laes9N7PqyvbW4q5w8c\nOVjOtx25WM7JYXNCKHFCKHFCKHFCKHFCKHFCKHFCKOecI/DXvofL+fH73uw56zS2lNe2u/W9Fw+9\nUc4PXD1czmcWL9U3YMPYnBBKnBBKnBBKnBBKnBBKnBBKnBDKOecIzH5xvZy//evjPWcLc4OdM26f\nqs9JW6/dqD9gcaDbM0Q2J4QSJ4QSJ4QSJ4QSJ4QSJ4RylDICK9eWy/mZdx/tOVs4PNo/2frhylw5\n39P4bqT359bZnBBKnBBKnBBKnBBKnBBKnBBKnBDKOecYbP/4997D+psrB3bPheZob8DQ2JwQSpwQ\nSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQyt9z3mY2v/xT/QPvbcxz0J/N\nCaHECaHECaHECaHECaHECaHECaGcc45B6/rNnrNXvp8vrz2589xA935hx+fl/HTj7oE+n+GxOSGU\nOCGUOCGUOCGUOCGUOCGUo5QxWP35Rs/ZhSsPlddO7zpfztvd+t7TzdX6B4hhc0IocUIocUIocUIo\ncUIocUIocUIo55xpus1y3O7W55SdRqecP7v123J+7NBzPWdzRy+W1zJcNieEEieEEieEEieEEieE\nEieEEieEcs4Z5v7jf9c/8NRgnz/b2lzO/7ljsM9neGxOCCVOCCVOCCVOCCVOCCVOCCVOCOWcM82l\nr8Z6+wf3LvWc3VzYwAfB5oRU4oRQ4oRQ4oRQ4oRQ4oRQ4oRQzjknzHRzUznv937Ofk7uPNdz9kyj\nfncow2VzQihxQihxQihxQihxQihxQihHKRNm9/uvlvOl549t0JMwajYnhBInhBInhBInhBInhBIn\nhBInhHLOOWG2/Da+36dT9+4o5yvXljfoSW4PNieEEieEEieEEieEEieEEieEEieEcs7JLXvko6vl\n/NO9u8v5yvKPw3yc/z2bE0KJE0KJE0KJE0KJE0KJE0KJE0I555ww3WY9b43w9+3rd31dzp9+pz7n\nbDw5xIe5DdicEEqcEEqcEEqcEEqcEEqcEMpRyoRpdut5p9EZ2b3bfe7d7XfOw7rYnBBKnBBKnBBK\nnBBKnBBKnBBKnBDKOeeE2fXBL+X8kwNby/kTM3/+53tfbrfL+R8n6lcEzja8InA9bE4IJU4IJU4I\nJU4IJU4IJU4IJU4I5ZxzwqwufVPOD555qZxf3vdWOX/syxd7zmZO3FleO7v4WTlnfWxOCCVOCCVO\nCCVOCCVOCCVOCCVOCNXsdnt/Gel8a3+fbyoFBnW2c2rNL/y1OSGUOCGUOCGUOCGUOCGUOCGUOCGU\nOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUOCGU\nOCGUOCGUOCGUOCFU+QpAYHxsTgglTgglTgglTgglTgglTgj1Lxgihs7DWo2eAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBh_pF1DRIwZ",
        "colab_type": "text"
      },
      "source": [
        "***Forward Propagation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpHbpOugN11z",
        "colab_type": "text"
      },
      "source": [
        "###Defining Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Pqv2oBN1Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(p):\n",
        "    s = 1 / (1 + np.exp(-p))\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tywlxBqmM4Rr",
        "colab_type": "text"
      },
      "source": [
        "####Defining Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mulu0zJwMq8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lossfunction(Y, Y_hat):\n",
        "\n",
        "    Loss_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
        "    m = Y.shape[1]\n",
        "    L = -(1/m) * Loss_sum\n",
        "\n",
        "    return L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8qw947pQhdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e7e27072-7592-4f1a-dbe5-f589ee83d411"
      },
      "source": [
        "learning_rate = 0.009\n",
        "\n",
        "Input_X = X_train\n",
        "Target_Y = Y_train\n",
        "\n",
        "new_x = Input_X.shape[0]\n",
        "d = Input_X.shape[1]\n",
        "\n",
        "W = np.random.randn(new_x, 1) * 0.01\n",
        "b = np.zeros((1, 1))\n",
        "\n",
        "for i in range(1000):\n",
        "    Z = np.matmul(W.T, Input_X) + b\n",
        "    A = sigmoid(Z)\n",
        "\n",
        "    cost = lossfunction(Target_Y, A)\n",
        "\n",
        "    dW = (1/d) * np.matmul(Input_X, (A-Target_Y).T)  #Derivative of weight\n",
        "    db = (1/d) * np.sum(A-Target_Y, axis=1, keepdims=True) #Derivative of bias\n",
        "\n",
        "    W = W - learning_rate * dW #Updated Weight\n",
        "    b = b - learning_rate * db #Updated Bias\n",
        "\n",
        "    if (i % 100 == 0):\n",
        "        print(\"Epoch\", i, \"cost: \", cost)\n",
        "\n",
        "print(\"Final cost:\", cost)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 cost:  0.8643654986173639\n",
            "Epoch 100 cost:  0.5184028731734912\n",
            "Epoch 200 cost:  0.48475417746856386\n",
            "Epoch 300 cost:  0.46976184561372014\n",
            "Epoch 400 cost:  0.4606073783845699\n",
            "Epoch 500 cost:  0.45413342695458303\n",
            "Epoch 600 cost:  0.44915594322980623\n",
            "Epoch 700 cost:  0.445122570555433\n",
            "Epoch 800 cost:  0.4417368769237799\n",
            "Epoch 900 cost:  0.4388231177664497\n",
            "Final cost: 0.43629300913260566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8I64VL5RcBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e60821d0-a586-4f37-9a75-fc2fcc9634aa"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Z = np.matmul(W.T, X_test) + b\n",
        "A = sigmoid(Z)\n",
        "\n",
        "pred = (A>.5)[0,:]\n",
        "label = (Y_test == 1)[0,:]\n",
        "\n",
        "print(confusion_matrix(pred, label))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8974   29]\n",
            " [  46  951]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUg0PBi0UCRu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e49bb5c7-d3ef-4e82-8ea0-7d274af89f4a"
      },
      "source": [
        "print(classification_report(pred, label))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      1.00      1.00      9003\n",
            "        True       0.97      0.95      0.96       997\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMxn5ya8QQDF",
        "colab_type": "text"
      },
      "source": [
        "###Adding Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JFWulv0NFEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_x = X_train.shape[0]\n",
        "new_h = 64\n",
        "learning_rate = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikkg86YCNH_S",
        "colab_type": "text"
      },
      "source": [
        "####Weights and Bias Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOmGUQaoNGqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = np.random.randn(new_h, new_x)\n",
        "b1 = np.zeros((new_h, 1))\n",
        "W2 = np.random.randn(digits, new_h)\n",
        "b2 = np.zeros((digits, 1))\n",
        "#print(W2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OL0F55qNcT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Input_X = X_train\n",
        "Target_Y = Y_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSsrM1LRNm8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "93fc9fcd-c334-4ae2-e13c-dc6cda738059"
      },
      "source": [
        "for i in range(1000):\n",
        "    Z1 = np.matmul(W1,Input_X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.matmul(W2,A1) + b2\n",
        "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
        "\n",
        "    cost = lossfunction(Target_Y, A2)\n",
        "\n",
        "    dZ2 = A2-Target_Y\n",
        "    #d = first 60000 samples out of 70000\n",
        "    dW2 = (1./d) * np.matmul(dZ2, A1.T)  #Derivatiove of Weight\n",
        "    db2 = (1./d) * np.sum(dZ2, axis=1, keepdims=True) #Derivative of Bias\n",
        "\n",
        "    dA1 = np.matmul(W2.T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
        "    dW1 = (1./d) * np.matmul(dZ1, Input_X.T)\n",
        "    db1 = (1./d) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "\n",
        "    if (i % 100 == 0):\n",
        "        print(\"Epoch\", i, \"cost: \", cost)\n",
        "\n",
        "print(\"Final:\", cost)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 cost:  14.961926263643658\n",
            "Epoch 100 cost:  0.8199658166190416\n",
            "Epoch 200 cost:  0.6159831630322086\n",
            "Epoch 300 cost:  0.5326631608411468\n",
            "Epoch 400 cost:  0.4845671180836123\n",
            "Epoch 500 cost:  0.4525620078128587\n",
            "Epoch 600 cost:  0.42895108259401454\n",
            "Epoch 700 cost:  0.4098254394023992\n",
            "Epoch 800 cost:  0.39398315534585\n",
            "Epoch 900 cost:  0.3807472028068692\n",
            "Final cost: 0.3691402242572656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBcaWqOjNASH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "71764998-7ad4-4206-9d74-d4f3490972cc"
      },
      "source": [
        "Z1 = np.matmul(W1, X_test) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1) + b2\n",
        "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
        "\n",
        "pred= np.argmax(A2, axis=0)\n",
        "label = np.argmax(Y_test, axis=0)\n",
        "\n",
        "print(confusion_matrix(pred, label))\n",
        "print(classification_report(pred, label))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 920    0   15    4    3   19   22    1    6   10]\n",
            " [   0 1096    5    3    3    6    2   18    7    3]\n",
            " [   5    3  893   23    9    6   29   17   16    6]\n",
            " [   8    7   33  874    3   36    2   13   46   12]\n",
            " [   1    0   13    3  857   16   11    8   14   73]\n",
            " [  22    3    5   39    4  721   27    4   39   14]\n",
            " [  12    3   20    5   19   21  856    3   13    3]\n",
            " [   6    1   19   10    6   11    0  916   18   37]\n",
            " [   5   22   25   36   10   42    9    7  788   17]\n",
            " [   1    0    4   13   68   14    0   41   27  834]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      1000\n",
            "           1       0.97      0.96      0.96      1143\n",
            "           2       0.87      0.89      0.88      1007\n",
            "           3       0.87      0.85      0.86      1034\n",
            "           4       0.87      0.86      0.87       996\n",
            "           5       0.81      0.82      0.81       878\n",
            "           6       0.89      0.90      0.89       955\n",
            "           7       0.89      0.89      0.89      1024\n",
            "           8       0.81      0.82      0.81       961\n",
            "           9       0.83      0.83      0.83      1002\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.87      0.87      0.87     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR8sLJMHXnO9",
        "colab_type": "text"
      },
      "source": [
        "***Results above*** show 88% Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIfyCdqAhN-B",
        "colab_type": "text"
      },
      "source": [
        "###Increased Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOiijAkNhNLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c17cdae9-6f74-4f5d-da38-198be801d5a5"
      },
      "source": [
        "for i in range(2000):\n",
        "    Z1 = np.matmul(W1,Input_X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.matmul(W2,A1) + b2\n",
        "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
        "\n",
        "    cost = lossfunction(Target_Y, A2)\n",
        "\n",
        "    dZ2 = A2-Target_Y\n",
        "    #d = first 60000 samples out of 70000\n",
        "    dW2 = (1./d) * np.matmul(dZ2, A1.T)  #Derivatiove of Weight\n",
        "    db2 = (1./d) * np.sum(dZ2, axis=1, keepdims=True) #Derivative of Bias\n",
        "\n",
        "    dA1 = np.matmul(W2.T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
        "    dW1 = (1./d) * np.matmul(dZ1, Input_X.T)\n",
        "    db1 = (1./d) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "\n",
        "    if (i % 100 == 0):\n",
        "        print(\"Epoch\", i, \"cost: \", cost)\n",
        "\n",
        "print(\"Final:\", cost)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 cost:  0.36903152173266945\n",
            "Epoch 100 cost:  0.35886843324142964\n",
            "Epoch 200 cost:  0.3499099299397331\n",
            "Epoch 300 cost:  0.34203089072217996\n",
            "Epoch 400 cost:  0.33496245170098093\n",
            "Epoch 500 cost:  0.3285667895038364\n",
            "Epoch 600 cost:  0.32282575603508934\n",
            "Epoch 700 cost:  0.31753375653819776\n",
            "Epoch 800 cost:  0.3128004910782973\n",
            "Epoch 900 cost:  0.30833399925951605\n",
            "Epoch 1000 cost:  0.3040478568911585\n",
            "Epoch 1100 cost:  0.2998658805999056\n",
            "Epoch 1200 cost:  0.29593978271934457\n",
            "Epoch 1300 cost:  0.2922770264070278\n",
            "Epoch 1400 cost:  0.28883227257686633\n",
            "Epoch 1500 cost:  0.28541016266495006\n",
            "Epoch 1600 cost:  0.2822570495874254\n",
            "Epoch 1700 cost:  0.27925231997500183\n",
            "Epoch 1800 cost:  0.2763870835458513\n",
            "Epoch 1900 cost:  0.273687052840769\n",
            "Final: 0.27112638886711954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6t_OhDlQCIN",
        "colab_type": "text"
      },
      "source": [
        "###Using Mini-Batch to improve the Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hXR-d8pQDK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(p):\n",
        "    s = 1. / (1. + np.exp(-p))\n",
        "    return s\n",
        "\n",
        "def lossfunction(Y, Y_hat):\n",
        "\n",
        "    Loss_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
        "    m = Y.shape[1]\n",
        "    L = -(1/m) * Loss_sum\n",
        "\n",
        "    return L\n",
        "\n",
        "def feed_forward(Input_X, params):\n",
        "\n",
        "    cache = {}\n",
        "\n",
        "    cache[\"Z1\"] = np.matmul(params[\"W1\"], Input_X) + params[\"b1\"]\n",
        "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
        "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
        "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
        "\n",
        "    return cache\n",
        "\n",
        "def back_propagate(Input_X, Target_Y, params, cache):\n",
        "\n",
        "    dZ2 = cache[\"A2\"] - Target_Y\n",
        "    dW2 = (1./m_batch) * np.matmul(dZ2, cache[\"A1\"].T)\n",
        "    db2 = (1./m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
        "    dW1 = (1./m_batch) * np.matmul(dZ1, X.T)\n",
        "    db1 = (1./m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7HbcmZYV9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d1ee812c-4996-4f1a-89d9-4923c8700144"
      },
      "source": [
        "np.random.seed(138)\n",
        "\n",
        "# hyperparameters\n",
        "n_x = X_train.shape[0]\n",
        "n_h = 64\n",
        "learning_rate = 4\n",
        "beta = .9\n",
        "batch_size = 128\n",
        "batches = -(-d // batch_size)\n",
        "\n",
        "# initialization\n",
        "params = { \"W1\": np.random.randn(n_h, n_x) * np.sqrt(1. / n_x),\n",
        "           \"b1\": np.zeros((n_h, 1)) * np.sqrt(1. / n_x),\n",
        "           \"W2\": np.random.randn(digits, n_h) * np.sqrt(1. / n_h),\n",
        "           \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / n_h) }\n",
        "\n",
        "V_dW1 = np.zeros(params[\"W1\"].shape)\n",
        "V_db1 = np.zeros(params[\"b1\"].shape)\n",
        "V_dW2 = np.zeros(params[\"W2\"].shape)\n",
        "V_db2 = np.zeros(params[\"b2\"].shape)\n",
        "\n",
        "# train\n",
        "for i in range(9):\n",
        "\n",
        "    permutation = np.random.permutation(X_train.shape[1])\n",
        "    X_train_shuffled = X_train[:, permutation]\n",
        "    Y_train_shuffled = Y_train[:, permutation]\n",
        "\n",
        "    for j in range(batches):\n",
        "\n",
        "        begin = j * batch_size\n",
        "        end = min(begin + batch_size, X_train.shape[1] - 1)\n",
        "        X = X_train_shuffled[:, begin:end]\n",
        "        Y = Y_train_shuffled[:, begin:end]\n",
        "        m_batch = end - begin\n",
        "\n",
        "        cache = feed_forward(X, params)\n",
        "        grads = back_propagate(X, Y, params, cache)\n",
        "\n",
        "        V_dW1 = (beta * V_dW1 + (1. - beta) * grads[\"dW1\"])\n",
        "        V_db1 = (beta * V_db1 + (1. - beta) * grads[\"db1\"])\n",
        "        V_dW2 = (beta * V_dW2 + (1. - beta) * grads[\"dW2\"])\n",
        "        V_db2 = (beta * V_db2 + (1. - beta) * grads[\"db2\"])\n",
        "\n",
        "        params[\"W1\"] = params[\"W1\"] - learning_rate * V_dW1\n",
        "        params[\"b1\"] = params[\"b1\"] - learning_rate * V_db1\n",
        "        params[\"W2\"] = params[\"W2\"] - learning_rate * V_dW2\n",
        "        params[\"b2\"] = params[\"b2\"] - learning_rate * V_db2\n",
        "\n",
        "    cache = feed_forward(X_train, params)\n",
        "    train_cost = lossfunction(Y_train, cache[\"A2\"])\n",
        "    cache = feed_forward(X_test, params)\n",
        "    test_cost = lossfunction(Y_test, cache[\"A2\"])\n",
        "    print(\"Epoch {}: training cost = {}, test cost = {}\".format(i+1 ,train_cost, test_cost))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: training cost = 0.4962803245963952, test cost = 0.48091539453166465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: training cost = 0.39458462420738116, test cost = 0.40380697954817973\n",
            "Epoch 3: training cost = 0.341913912642149, test cost = 0.331445194591507\n",
            "Epoch 4: training cost = 0.3277252587816243, test cost = 0.3229068590873622\n",
            "Epoch 5: training cost = 0.30976712723064515, test cost = 0.3084515641177357\n",
            "Epoch 6: training cost = 0.31149298267817516, test cost = 0.30891923277155375\n",
            "Epoch 7: training cost = 0.2895015530412461, test cost = 0.29453009460204144\n",
            "Epoch 8: training cost = 0.2945754512986746, test cost = 0.30228857933465053\n",
            "Epoch 9: training cost = 0.2661874741752893, test cost = 0.27950588662059345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxkhu5YOYdTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "96cdde32-6592-4a3f-b126-20e9370c4cad"
      },
      "source": [
        "cache = feed_forward(X_test, params)\n",
        "predictions = np.argmax(cache[\"A2\"], axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94      1053\n",
            "           1       0.98      0.97      0.98      1140\n",
            "           2       0.89      0.95      0.92       970\n",
            "           3       0.92      0.89      0.91      1038\n",
            "           4       0.96      0.88      0.92      1061\n",
            "           5       0.85      0.93      0.89       821\n",
            "           6       0.93      0.95      0.94       944\n",
            "           7       0.96      0.87      0.91      1133\n",
            "           8       0.89      0.87      0.88      1000\n",
            "           9       0.79      0.95      0.86       840\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.91      0.92      0.91     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnAyEgEKZKx2",
        "colab_type": "text"
      },
      "source": [
        "***Results Above*** show accuracy improved from 87% to 92%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1FBjPcqZVtp",
        "colab_type": "text"
      },
      "source": [
        "###Using Relu trying to improve accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTrfDM6zZJs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "    y=x\n",
        "    for i in range(x.shape[0]):\n",
        "        y[i]=np.maximum(0,x[i])\n",
        "    return y\n",
        "\n",
        "def relu_derivative(x):\n",
        "    y=x\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            if(x[i][j]>0.0):\n",
        "                y[i][j]= 1.0\n",
        "            else:\n",
        "                y[i][j]= 0.0\n",
        "    return y\n",
        "\n",
        "def lossfunction(Y, Y_hat):\n",
        "\n",
        "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
        "    m = Y.shape[1]\n",
        "    L = -(1./m) * L_sum\n",
        "\n",
        "    return L\n",
        "\n",
        "def feed_forward(Input_X, params):\n",
        "\n",
        "    cache = {}\n",
        "\n",
        "    cache[\"Z1\"] = np.matmul(params[\"W1\"], Input_X) + params[\"b1\"]\n",
        "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
        "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
        "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
        "\n",
        "    return cache\n",
        "\n",
        "\n",
        "def back_propagate(Input_X, Target_Y, params, cache):\n",
        "\n",
        "    dZ2 = cache[\"A2\"] - Target_Y\n",
        "    dW2 = (1./m_batch) * np.matmul(dZ2, cache[\"A1\"].T)\n",
        "    db2 = (1./m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
        "    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
        "    dW1 = (1./m_batch) * np.matmul(dZ1, X.T)\n",
        "    db1 = (1./m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHp6eGuKZdQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f5be94bb-8b0f-4021-d168-8e04e8e28a25"
      },
      "source": [
        "np.random.seed(138)\n",
        "\n",
        "# Hyperparameters\n",
        "new_x = X_train.shape[0]\n",
        "new_h = 64\n",
        "learning_rate = 1\n",
        "beta = .9\n",
        "batch_size = 128\n",
        "batches = -(-d // batch_size)\n",
        "\n",
        "# Weight and Bias Initialization\n",
        "params = { \"W1\": np.random.randn(new_h, new_x) * np.sqrt(1. / new_x),\n",
        "           \"b1\": np.zeros((new_h, 1)) * np.sqrt(1. / new_x),\n",
        "           \"W2\": np.random.randn(digits, new_h) * np.sqrt(1. / new_h),\n",
        "           \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / new_h) }\n",
        "\n",
        "V_dW1 = np.zeros(params[\"W1\"].shape)\n",
        "V_db1 = np.zeros(params[\"b1\"].shape)\n",
        "V_dW2 = np.zeros(params[\"W2\"].shape)\n",
        "V_db2 = np.zeros(params[\"b2\"].shape)\n",
        "\n",
        "# Network Training\n",
        "for i in range(9):\n",
        "\n",
        "    permutation = np.random.permutation(X_train.shape[1])\n",
        "    X_train_shuffled = X_train[:, permutation]\n",
        "    Y_train_shuffled = Y_train[:, permutation]\n",
        "\n",
        "    for j in range(batches):\n",
        "\n",
        "        begin = j * batch_size\n",
        "        end = min(begin + batch_size, X_train.shape[1] - 1)\n",
        "        X = X_train_shuffled[:, begin:end]\n",
        "        Y = Y_train_shuffled[:, begin:end]\n",
        "        m_batch = end - begin\n",
        "\n",
        "        cache = feed_forward(X, params)\n",
        "        grads = back_propagate(X, Y, params, cache)\n",
        "\n",
        "        V_dW1 = (beta * V_dW1 + (1. - beta) * grads[\"dW1\"])\n",
        "        V_db1 = (beta * V_db1 + (1. - beta) * grads[\"db1\"])\n",
        "        V_dW2 = (beta * V_dW2 + (1. - beta) * grads[\"dW2\"])\n",
        "        V_db2 = (beta * V_db2 + (1. - beta) * grads[\"db2\"])\n",
        "\n",
        "        params[\"W1\"] = params[\"W1\"] - learning_rate * V_dW1\n",
        "        params[\"b1\"] = params[\"b1\"] - learning_rate * V_db1\n",
        "        params[\"W2\"] = params[\"W2\"] - learning_rate * V_dW2\n",
        "        params[\"b2\"] = params[\"b2\"] - learning_rate * V_db2\n",
        "\n",
        "    cache = feed_forward(X_train, params)\n",
        "    train_cost = lossfunction(Y_train, cache[\"A2\"])\n",
        "    cache = feed_forward(X_test, params)\n",
        "    test_cost = lossfunction(Y_test, cache[\"A2\"])\n",
        "    print(\"Epoch {}: training cost = {}, test cost = {}\".format(i+1 ,train_cost, test_cost))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: training cost = 0.23153900925903195, test cost = 0.2320361056489676\n",
            "Epoch 2: training cost = 0.193992468052257, test cost = 0.20890290429013314\n",
            "Epoch 3: training cost = 0.17285931081743286, test cost = 0.18957740092953707\n",
            "Epoch 4: training cost = 0.1729438779376178, test cost = 0.18530297489859385\n",
            "Epoch 5: training cost = 0.14797202937781936, test cost = 0.1676441204285113\n",
            "Epoch 6: training cost = 0.14133659762671638, test cost = 0.16382576936614224\n",
            "Epoch 7: training cost = 0.1332719639095687, test cost = 0.15815738738491944\n",
            "Epoch 8: training cost = 0.12287761763292579, test cost = 0.1463151181322346\n",
            "Epoch 9: training cost = 0.13078023330310556, test cost = 0.15919833013055423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ytuDlXtZsm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "66bc2b38-a697-4c86-8532-312e59f3da57"
      },
      "source": [
        "cache = feed_forward(X_test, params)\n",
        "pred = np.argmax(cache[\"A2\"], axis=0)\n",
        "label = np.argmax(Y_test, axis=0)\n",
        "\n",
        "print(classification_report(pred, label))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97      1024\n",
            "           1       0.99      0.98      0.99      1141\n",
            "           2       0.95      0.96      0.95      1019\n",
            "           3       0.92      0.95      0.94       975\n",
            "           4       0.95      0.95      0.95       987\n",
            "           5       0.93      0.94      0.94       876\n",
            "           6       0.97      0.96      0.96       961\n",
            "           7       0.95      0.95      0.95      1028\n",
            "           8       0.94      0.92      0.93       999\n",
            "           9       0.92      0.94      0.93       990\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.95      0.95     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrKiane9a9UW",
        "colab_type": "text"
      },
      "source": [
        "###Results above show 95% Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th4N1XKdq-9c",
        "colab_type": "text"
      },
      "source": [
        "####Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhQXXQFZafcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9a3faf55-0717-4f7e-90a8-a0578d363938"
      },
      "source": [
        "print(confusion_matrix(pred, label))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 968    0    9    4    5    8   11    3    8    8]\n",
            " [   0 1121    5    2    1    1    2    6    1    2]\n",
            " [   2    2  978   11    3    3    1   16    2    1]\n",
            " [   1    2    5  928    0   16    1    6    9    7]\n",
            " [   0    0    4    0  937    1    2    3    6   34]\n",
            " [   4    0    0   20    0  827   10    1   11    3]\n",
            " [   1    0    6    4    6   13  925    0    6    0]\n",
            " [   0    1    8   12    6    7    1  973    7   13]\n",
            " [   3    9   17   20    6    8    5    2  918   11]\n",
            " [   1    0    0    9   18    8    0   18    6  930]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}